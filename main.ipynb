{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train gpt-neo-2.7B using deepspeed and transformers (27/9/21)!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c70912",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure deepspeed requirements are met (asyncio is not necessary)\n",
    "!ds_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519365e",
   "metadata": {},
   "source": [
    "Next we use deepspeed to execute training for train and validation sets\n",
    "\n",
    "Note: checkpointing is possible using `save_steps`, but a large amount of disk space is used so we disable it for now.\n",
    "However if you're using a preemptible instance, this might be a good idea.\n",
    "\n",
    "If evaluation is happening too frequently you can increase `eval_steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee740bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-26 02:16:07,205] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2021-09-26 02:16:07,944] [INFO] [runner.py:360:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 run_clm.py --deepspeed ds_config_gptneo.json --model_name_or_path EleutherAI/gpt-neo-2.7B --train_file train.csv --validation_file validation.csv --do_train --do_eval --fp16 --overwrite_cache --overwrite_output_dir --evaluation_strategy=steps --output_dir jy-chat-model --num_train_epochs 1 --eval_steps 30 --gradient_accumulation_steps 2 --per_device_train_batch_size 4 --use_fast_tokenizer False --learning_rate 5e-06 --warmup_steps 10\n",
      "[2021-09-26 02:16:08,764] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2021-09-26 02:16:08,764] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2021-09-26 02:16:08,764] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2021-09-26 02:16:08,764] [INFO] [launch.py:102:main] dist_world_size=1\n",
      "[2021-09-26 02:16:08,764] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "[2021-09-26 02:16:10,600] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "09/26/2021 02:16:10 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/26/2021 02:16:10 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=ds_config_gptneo.json,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=30,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=2,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=jy-chat-model/runs/Sep26_02-16-10_instance-2,\n",
      "logging_first_step=False,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=jy-chat-model,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=jy-chat-model,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=jy-chat-model,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=10,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/26/2021 02:16:10 - WARNING - datasets.builder -   Using custom data configuration default-72d80fb35ba93836\n",
      "09/26/2021 02:16:10 - WARNING - datasets.builder -   Reusing dataset csv (/home/nicholaslyz_work/.cache/huggingface/datasets/csv/default-72d80fb35ba93836/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 852.93it/s]\n",
      "[INFO|configuration_utils.py:561] 2021-09-26 02:16:10,975 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/config.json from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/3c80ef2946e1aacc6dd37cb986ea989c29c92775701655bedf14d8791825a30b.f1ede5af01beb85af6cba189a5671dbac3fe256282f737ff0fedf1db882ca729\n",
      "[INFO|configuration_utils.py:598] 2021-09-26 02:16:10,976 >> Model config GPTNeoConfig {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      16\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 20,\n",
      "  \"num_layers\": 32,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.10.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:561] 2021-09-26 02:16:11,289 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/config.json from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/3c80ef2946e1aacc6dd37cb986ea989c29c92775701655bedf14d8791825a30b.f1ede5af01beb85af6cba189a5671dbac3fe256282f737ff0fedf1db882ca729\n",
      "[INFO|configuration_utils.py:598] 2021-09-26 02:16:11,290 >> Model config GPTNeoConfig {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      16\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 20,\n",
      "  \"num_layers\": 32,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.10.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1739] 2021-09-26 02:16:12,433 >> loading file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/vocab.json from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/d4455fdc7c8e2bcf94a0bfe134b748a93c37ecadb7b8f6b0eb508ffdd433a61e.a1b97b074a5ac71fad0544c8abc1b3581803d73832476184bde6cff06a67b6bb\n",
      "[INFO|tokenization_utils_base.py:1739] 2021-09-26 02:16:12,433 >> loading file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/merges.txt from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/5660be25091706bde0cfb60f17ae72c7a2aa40223d68954d4d8ffd1fc6995643.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "[INFO|tokenization_utils_base.py:1739] 2021-09-26 02:16:12,433 >> loading file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1739] 2021-09-26 02:16:12,433 >> loading file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/special_tokens_map.json from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/953b5ce47652cf8b6e945b3570bfa7621164c337e05419b954dbe0a4d16a7480.3ae9ae72462581d20e36bc528e9c47bb30cd671bb21add40ca0b24a0be9fac22\n",
      "[INFO|tokenization_utils_base.py:1739] 2021-09-26 02:16:12,433 >> loading file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/tokenizer_config.json from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/57ccc3b8af045ea106fffa36bcc8b764e9702b5f4c1f7b3aad70ccfcaa931221.c31b6b7d3225be0c43bc0f8e5d84d03a8b49fdb6b9f6009bbfff1f9cc5ec18bc\n",
      "[INFO|tokenization_utils_base.py:1739] 2021-09-26 02:16:12,433 >> loading file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|configuration_utils.py:561] 2021-09-26 02:16:12,589 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/config.json from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/3c80ef2946e1aacc6dd37cb986ea989c29c92775701655bedf14d8791825a30b.f1ede5af01beb85af6cba189a5671dbac3fe256282f737ff0fedf1db882ca729\n",
      "[INFO|configuration_utils.py:598] 2021-09-26 02:16:12,590 >> Model config GPTNeoConfig {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      16\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 20,\n",
      "  \"num_layers\": 32,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.10.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1279] 2021-09-26 02:16:12,838 >> loading weights file https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/pytorch_model.bin from cache at /home/nicholaslyz_work/.cache/huggingface/transformers/0839a11efa893f2a554f8f540f904b0db0e5320a2b1612eb02c3fd25471c189a.a144c17634fa6a7823e398888396dd623e204dce9e33c3175afabfbf24bd8f56\n",
      "[INFO|modeling_utils.py:1524] 2021-09-26 02:19:11,746 >> All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:1533] 2021-09-26 02:19:11,746 >> All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-2.7B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n",
      "  0%|                                                     | 0/1 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:3265] 2021-09-26 02:19:20,180 >> Token indices sequence length is longer than the specified maximum sequence length for this model (2514767 > 2048). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.80s/ba]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26ba/s]\n",
      "run_clm.py:361: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
      "09/26/2021 02:19:22 - WARNING - __main__ -   The tokenizer picked seems to have a very large `model_max_length` (2048). Picking 1024 instead. You can change that default value by passing --block_size xxx.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/ba]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.93ba/s]\n",
      "[INFO|trainer.py:414] 2021-09-26 02:19:24,590 >> Using amp fp16 backend\n",
      "[2021-09-26 02:19:24,593] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.3, git-hash=unknown, git-branch=unknown\n",
      "[2021-09-26 02:19:29,328] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
      "[2021-09-26 02:19:29,328] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
      "[2021-09-26 02:19:29,329] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
      "[2021-09-26 02:19:29,330] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0]\n",
      "[2021-09-26 02:19:29,330] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
      "[2021-09-26 02:19:29,381] [INFO] [engine.py:198:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "Installed CUDA version 11.0 does not match the version torch was compiled with 11.1 but since the APIs are compatible, accepting this combination\n",
      "Using /home/nicholaslyz_work/.cache/torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/nicholaslyz_work/.cache/torch_extensions/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.5173313617706299 seconds\n",
      "Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "Config: alpha=0.000005, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2021-09-26 02:19:31,444] [INFO] [engine.py:823:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2021-09-26 02:19:31,475] [INFO] [engine.py:830:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2021-09-26 02:19:31,475] [INFO] [utils.py:44:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2021-09-26 02:19:31,476] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
      "[2021-09-26 02:19:31,476] [INFO] [stage2.py:111:__init__] Reduce bucket size 200000000.0\n",
      "[2021-09-26 02:19:31,476] [INFO] [stage2.py:112:__init__] Allgather bucket size 200000000.0\n",
      "[2021-09-26 02:19:31,476] [INFO] [stage2.py:113:__init__] CPU Offload: True\n",
      "[2021-09-26 02:19:31,476] [INFO] [stage2.py:114:__init__] Round robin gradient partitioning: False\n",
      "Using /home/nicholaslyz_work/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /home/nicholaslyz_work/.cache/torch_extensions/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.3200345039367676 seconds\n",
      "Rank: 0 partition count [1] and sizes[(2651307520, False)] \n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[2021-09-26 02:19:38,382] [INFO] [utils.py:714:see_memory_usage] Before initializing optimizer states\n",
      "[2021-09-26 02:19:38,383] [INFO] [utils.py:719:see_memory_usage] MA 5.24 GB         Max_MA 5.24 GB         CA 10.16 GB         Max_CA 10 GB \n",
      "[2021-09-26 02:19:38,383] [INFO] [utils.py:724:see_memory_usage] CPU Virtual Memory:  used = 19.05 GB, percent = 22.8%\n",
      "[2021-09-26 02:19:45,510] [INFO] [utils.py:714:see_memory_usage] After initializing optimizer states\n",
      "[2021-09-26 02:19:45,511] [INFO] [utils.py:719:see_memory_usage] MA 5.24 GB         Max_MA 5.24 GB         CA 10.16 GB         Max_CA 10 GB \n",
      "[2021-09-26 02:19:45,511] [INFO] [utils.py:724:see_memory_usage] CPU Virtual Memory:  used = 48.9 GB, percent = 58.5%\n",
      "[2021-09-26 02:19:45,511] [INFO] [stage2.py:473:__init__] optimizer state initialized\n",
      "[2021-09-26 02:19:45,581] [INFO] [utils.py:714:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2021-09-26 02:19:45,582] [INFO] [utils.py:719:see_memory_usage] MA 5.24 GB         Max_MA 5.24 GB         CA 10.16 GB         Max_CA 10 GB \n",
      "[2021-09-26 02:19:45,582] [INFO] [utils.py:724:see_memory_usage] CPU Virtual Memory:  used = 48.9 GB, percent = 58.5%\n",
      "[2021-09-26 02:19:45,583] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2021-09-26 02:19:45,583] [INFO] [engine.py:546:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2021-09-26 02:19:45,583] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f2bab8811d0>\n",
      "[2021-09-26 02:19:45,583] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-06], mom=[[0.9, 0.999]]\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   amp_params ................... False\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
      "[2021-09-26 02:19:45,583] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   dump_state ................... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   fp16_enabled ................. True\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   global_rank .................. 0\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 2\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   gradient_clipping ............ 1.0\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 65536\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   optimizer_name ............... adamw\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   optimizer_params ............. {'lr': 5e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   pld_params ................... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
      "[2021-09-26 02:19:45,584] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   scheduler_name ............... WarmupLR\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-06, 'warmup_num_steps': 10}\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   steps_per_print .............. 2000\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   train_batch_size ............. 8\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   world_size ................... 1\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   zero_config .................. {\n",
      "    \"stage\": 2, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 2.000000e+08, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 2.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": true, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": false, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_fp16_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   zero_enabled ................. True\n",
      "[2021-09-26 02:19:45,585] [INFO] [config.py:944:print]   zero_optimization_stage ...... 2\n",
      "[2021-09-26 02:19:45,586] [INFO] [config.py:951:print]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-06, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-06, \n",
      "            \"warmup_num_steps\": 10\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"cpu_offload\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 8, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "Using /home/nicholaslyz_work/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0004010200500488281 seconds\n",
      "[INFO|trainer.py:1168] 2021-09-26 02:19:45,586 >> ***** Running training *****\n",
      "[INFO|trainer.py:1169] 2021-09-26 02:19:45,587 >>   Num examples = 2455\n",
      "[INFO|trainer.py:1170] 2021-09-26 02:19:45,587 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1171] 2021-09-26 02:19:45,587 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1172] 2021-09-26 02:19:45,587 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1173] 2021-09-26 02:19:45,587 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:1174] 2021-09-26 02:19:45,587 >>   Total optimization steps = 307\n",
      " 10%|████                                      | 30/307 [02:28<22:27,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:22:14,310 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:22:14,310 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:22:14,310 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.41it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.10it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.68it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:09,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.17it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.17it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.3212890625, 'eval_runtime': 15.5232, 'eval_samples_per_second': 17.393, 'eval_steps_per_second': 2.19, 'epoch': 0.1}\n",
      " 10%|████                                      | 30/307 [02:44<22:27,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 20%|████████▏                                 | 60/307 [05:10<19:59,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:24:55,666 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:24:55,666 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:24:55,666 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.38it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.09it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.18it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.18it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.2763671875, 'eval_runtime': 15.5122, 'eval_samples_per_second': 17.406, 'eval_steps_per_second': 2.192, 'epoch': 0.2}\n",
      " 20%|████████▏                                 | 60/307 [05:25<19:59,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 29%|████████████▎                             | 90/307 [07:51<17:35,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:27:37,033 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:27:37,033 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:27:37,033 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.38it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.08it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.18it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.18it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.2568359375, 'eval_runtime': 15.5133, 'eval_samples_per_second': 17.404, 'eval_steps_per_second': 2.192, 'epoch': 0.29}\n",
      " 29%|████████████▎                             | 90/307 [08:06<17:35,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 39%|████████████████                         | 120/307 [10:32<15:11,  4.87s/it][INFO|trainer.py:2181] 2021-09-26 02:30:18,412 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:30:18,412 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:30:18,412 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.37it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.09it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.17it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.17it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.17it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.244140625, 'eval_runtime': 15.5249, 'eval_samples_per_second': 17.391, 'eval_steps_per_second': 2.19, 'epoch': 0.39}\n",
      " 39%|████████████████                         | 120/307 [10:48<15:11,  4.87s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 49%|████████████████████                     | 150/307 [13:14<12:43,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:32:59,798 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:32:59,798 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:32:59,798 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.38it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.08it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.18it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.18it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.2353515625, 'eval_runtime': 15.5105, 'eval_samples_per_second': 17.408, 'eval_steps_per_second': 2.192, 'epoch': 0.49}\n",
      " 49%|████████████████████                     | 150/307 [13:29<12:43,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 59%|████████████████████████                 | 180/307 [15:55<10:16,  4.85s/it][INFO|trainer.py:2181] 2021-09-26 02:35:40,970 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:35:40,970 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:35:40,970 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.38it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.09it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.18it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.18it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.2255859375, 'eval_runtime': 15.5174, 'eval_samples_per_second': 17.4, 'eval_steps_per_second': 2.191, 'epoch': 0.59}\n",
      " 59%|████████████████████████                 | 180/307 [16:10<10:16,  4.85s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 68%|████████████████████████████             | 210/307 [18:36<07:51,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:38:22,372 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:38:22,372 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:38:22,372 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.38it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.09it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.26it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.17it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.17it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.17it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.17it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.17it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.2177734375, 'eval_runtime': 15.5231, 'eval_samples_per_second': 17.393, 'eval_steps_per_second': 2.19, 'epoch': 0.68}\n",
      " 68%|████████████████████████████             | 210/307 [18:52<07:51,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 78%|████████████████████████████████         | 240/307 [21:18<05:28,  4.91s/it]\u001B[A[INFO|trainer.py:2181] 2021-09-26 02:41:03,867 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:41:03,868 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:41:03,868 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.37it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.09it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.17it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.17it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.17it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.17it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.17it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.17it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.17it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.17it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.21484375, 'eval_runtime': 15.5245, 'eval_samples_per_second': 17.392, 'eval_steps_per_second': 2.19, 'epoch': 0.78}\n",
      " 78%|████████████████████████████████         | 240/307 [21:33<05:28,  4.91s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 88%|████████████████████████████████████     | 270/307 [23:59<02:59,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:43:45,259 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:43:45,259 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:43:45,260 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.37it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.09it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.19it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.18it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.18it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.208984375, 'eval_runtime': 15.5157, 'eval_samples_per_second': 17.402, 'eval_steps_per_second': 2.191, 'epoch': 0.88}\n",
      " 88%|████████████████████████████████████     | 270/307 [24:15<02:59,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      " 98%|████████████████████████████████████████ | 300/307 [26:41<00:33,  4.86s/it][INFO|trainer.py:2181] 2021-09-26 02:46:26,716 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:46:26,717 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:46:26,717 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001B[A\n",
      "  6%|██▌                                         | 2/34 [00:00<00:07,  4.38it/s]\u001B[A\n",
      "  9%|███▉                                        | 3/34 [00:00<00:10,  3.08it/s]\u001B[A\n",
      " 12%|█████▏                                      | 4/34 [00:01<00:11,  2.67it/s]\u001B[A\n",
      " 15%|██████▍                                     | 5/34 [00:01<00:11,  2.48it/s]\u001B[A\n",
      " 18%|███████▊                                    | 6/34 [00:02<00:11,  2.37it/s]\u001B[A\n",
      " 21%|█████████                                   | 7/34 [00:02<00:11,  2.31it/s]\u001B[A\n",
      " 24%|██████████▎                                 | 8/34 [00:03<00:11,  2.27it/s]\u001B[A\n",
      " 26%|███████████▋                                | 9/34 [00:03<00:11,  2.24it/s]\u001B[A\n",
      " 29%|████████████▋                              | 10/34 [00:04<00:10,  2.22it/s]\u001B[A\n",
      " 32%|█████████████▉                             | 11/34 [00:04<00:10,  2.21it/s]\u001B[A\n",
      " 35%|███████████████▏                           | 12/34 [00:05<00:10,  2.20it/s]\u001B[A\n",
      " 38%|████████████████▍                          | 13/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 41%|█████████████████▋                         | 14/34 [00:05<00:09,  2.19it/s]\u001B[A\n",
      " 44%|██████████████████▉                        | 15/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 47%|████████████████████▏                      | 16/34 [00:06<00:08,  2.18it/s]\u001B[A\n",
      " 50%|█████████████████████▌                     | 17/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:07<00:07,  2.18it/s]\u001B[A\n",
      " 56%|████████████████████████                   | 19/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:08<00:06,  2.18it/s]\u001B[A\n",
      " 62%|██████████████████████████▌                | 21/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 65%|███████████████████████████▊               | 22/34 [00:09<00:05,  2.18it/s]\u001B[A\n",
      " 68%|█████████████████████████████              | 23/34 [00:10<00:05,  2.18it/s]\u001B[A\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:10<00:04,  2.18it/s]\u001B[A\n",
      " 74%|███████████████████████████████▌           | 25/34 [00:11<00:04,  2.18it/s]\u001B[A\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:11<00:03,  2.18it/s]\u001B[A\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:12<00:02,  2.18it/s]\u001B[A\n",
      " 88%|█████████████████████████████████████▉     | 30/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:13<00:01,  2.18it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████▍  | 32/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      " 97%|█████████████████████████████████████████▋ | 33/34 [00:14<00:00,  2.18it/s]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_loss': 1.203125, 'eval_runtime': 15.5126, 'eval_samples_per_second': 17.405, 'eval_steps_per_second': 2.192, 'epoch': 0.98}\n",
      " 98%|████████████████████████████████████████ | 300/307 [26:56<00:33,  4.86s/it]\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.19it/s]\u001B[A\n",
      "100%|█████████████████████████████████████████| 307/307 [27:30<00:00,  5.35s/it][INFO|trainer.py:1366] 2021-09-26 02:47:16,053 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1650.4661, 'train_samples_per_second': 1.487, 'train_steps_per_second': 0.186, 'train_loss': 1.2840619910423452, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████| 307/307 [27:30<00:00,  5.38s/it]\n",
      "[INFO|trainer.py:1935] 2021-09-26 02:47:16,057 >> Saving model checkpoint to jy-chat-model\n",
      "[INFO|configuration_utils.py:391] 2021-09-26 02:47:16,058 >> Configuration saved in jy-chat-model/config.json\n",
      "[INFO|modeling_utils.py:1001] 2021-09-26 02:47:37,448 >> Model weights saved in jy-chat-model/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2020] 2021-09-26 02:47:37,449 >> tokenizer config file saved in jy-chat-model/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2026] 2021-09-26 02:47:37,449 >> Special tokens file saved in jy-chat-model/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     1.2841\n",
      "  train_runtime            = 0:27:30.46\n",
      "  train_samples            =       2455\n",
      "  train_samples_per_second =      1.487\n",
      "  train_steps_per_second   =      0.186\n",
      "09/26/2021 02:47:37 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:2181] 2021-09-26 02:47:37,589 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2183] 2021-09-26 02:47:37,589 >>   Num examples = 270\n",
      "[INFO|trainer.py:2186] 2021-09-26 02:47:37,589 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 34/34 [00:15<00:00,  2.20it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     1.2051\n",
      "  eval_runtime            = 0:00:15.51\n",
      "  eval_samples            =        270\n",
      "  eval_samples_per_second =     17.404\n",
      "  eval_steps_per_second   =      2.192\n",
      "  perplexity              =      3.337\n"
     ]
    }
   ],
   "source": [
    "!deepspeed --num_gpus=1 run_clm.py \\\n",
    "--deepspeed ds_config_gptneo.json \\\n",
    "--model_name_or_path EleutherAI/gpt-neo-2.7B \\\n",
    "--train_file train.csv \\\n",
    "--validation_file validation.csv \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--fp16 \\\n",
    "--overwrite_cache \\\n",
    "--overwrite_output_dir \\\n",
    "--evaluation_strategy=\"steps\" \\\n",
    "--output_dir chat-model \\\n",
    "--num_train_epochs 1 \\\n",
    "--eval_steps 30 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--per_device_train_batch_size 4 \\\n",
    "--use_fast_tokenizer False \\\n",
    "--learning_rate 5e-06 \\\n",
    "--warmup_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's evaluate the model with some prompts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8aac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import deepspeed\n",
    "import torch\n",
    "from transformers import GPTNeoForCausalLM, AutoTokenizer\n",
    "\n",
    "# casting to fp16 \"half\" gives a large speedup during model loading\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"chat-model\").half().to(\"cuda:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"chat-model\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# using deepspeed inference is optional: it gives about a 2x speed up\n",
    "deepspeed.init_inference(model, mp_size=1, dtype=torch.half, replace_method='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb54f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_deepspeed(text):\n",
    "    start_time = time.time()\n",
    "    input_ids = tokenizer(text, padding=True, return_tensors='pt').to('cuda:0').input_ids\n",
    "    prompt_length = len(tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "    gen_tokens = model.generate(input_ids,\n",
    "                                top_p=0.9,\n",
    "                                temperature=0.9,\n",
    "                                max_length=prompt_length + 300,\n",
    "                                do_sample=True,\n",
    "                                use_cache=True)  # Without this you get a dimension error\n",
    "\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0][prompt_length:]\n",
    "\n",
    "    print(f'Took {time.time() - start_time:.2f}s')\n",
    "    print(f\"\\033[1m{text}\\033[0m{gen_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15afa9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 12.70s\n",
      "\u001B[1m2021-09-19T22:17:15 Nicholas L: I don't love you anymore\n",
      "\n",
      "2021-09-19T22:17:21 Jing\u001B[0m❤️: you know i’ve thought about this before\r\n",
      "\r\n",
      "2021-09-19T22:17:30 Jing❤️: what you said and what you didn’t say\r\n",
      "\r\n",
      "2021-09-19T22:17:41 Jing❤️: how you said it\r\n",
      "\r\n",
      "2021-09-19T22:17:55 Jing❤️: how you meant it\r\n",
      "\r\n",
      "2021-09-19T22:18:07 Nicholas L: Hmm\r\n",
      "\r\n",
      "2021-09-19T22:18:19 Jing❤️: i was thinking about it today\r\n",
      "\r\n",
      "2021-09-19T22:18:24 Jing❤️: the way you said it\r\n",
      "\r\n",
      "2021-09-19T22:18:31 Jing❤️: it hurt\r\n",
      "\r\n",
      "2021-09-19T22:18:38 Jing❤️: and i’ve been hurt before\r\n",
      "\r\n",
      "2021-09-19T22:18:42 Nicholas L: No.\r\n",
      "\r\n",
      "2021-09-19T22:18:46 Nicholas L: I don't believe you\r\n",
      "\r\n",
      "2021-09-19T22:18:52 Jing❤️: i know\r\n",
      "\r\n",
      "2021-09-19T22:18:56 Nicholas L: I never said that\r\n",
      "\r\n",
      "2021-09-19T22:18:57 Jing❤️: you’ve hurt me before\r\n",
      "\r\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "infer_deepspeed(\"\"\"Person A: Some text\n",
    "\n",
    "Person B: Some reply\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}